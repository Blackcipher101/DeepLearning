{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Song.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYg4rJuIn6m02xRbMdpPGQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blackcipher101/DeepLearning/blob/master/Song.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooHCHXd147Tl"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAg4Jirr7dTs",
        "outputId": "c14e4f05-5cd2-45f1-fb0e-2ecd3dba2e59"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-28 17:55:29--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.218.101, 172.217.218.100, 172.217.218.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.218.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bmadqr138tak6pvsrenbrpq7p6mkrs23/1606586100000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-11-28 17:55:32--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bmadqr138tak6pvsrenbrpq7p6mkrs23/1606586100000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv       [    <=>             ]  69.08M   103MB/s    in 0.7s    \n",
            "\n",
            "2020-11-28 17:55:33 (103 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMNvVSBr7fh2"
      },
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXJvTl6Z7fl7",
        "outputId": "8a511268-45e8-4863-beec-60c3e706fdc2"
      },
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UJwOrbf9Bvq"
      },
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NkHyW0i7fn_",
        "outputId": "460e5144-a688-48b3-bc8a-7c99c0ff4a97"
      },
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Tryi9B7fsu",
        "outputId": "028e8db2-bcd2-49eb-f45e-ccde0cd785c7"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.9858 - accuracy: 0.0333\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.4358 - accuracy: 0.0363\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.3711 - accuracy: 0.0404\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.3261 - accuracy: 0.0399\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.2594 - accuracy: 0.0373\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.1824 - accuracy: 0.0394\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.1096 - accuracy: 0.0580\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.0369 - accuracy: 0.0651\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.9543 - accuracy: 0.0651\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.8617 - accuracy: 0.0782\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.7641 - accuracy: 0.0863\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.6841 - accuracy: 0.0898\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5920 - accuracy: 0.0918\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5143 - accuracy: 0.0984\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.4270 - accuracy: 0.1044\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.3447 - accuracy: 0.1140\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.2643 - accuracy: 0.1387\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.1899 - accuracy: 0.1347\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.1104 - accuracy: 0.1438\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.0486 - accuracy: 0.1640\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.9806 - accuracy: 0.1756\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.8874 - accuracy: 0.1912\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.8170 - accuracy: 0.2043\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.7479 - accuracy: 0.2321\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6815 - accuracy: 0.2422\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6146 - accuracy: 0.2558\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.5387 - accuracy: 0.2775\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4984 - accuracy: 0.2856\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4263 - accuracy: 0.2941\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.3512 - accuracy: 0.3133\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2870 - accuracy: 0.3184\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2291 - accuracy: 0.3350\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1719 - accuracy: 0.3461\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1009 - accuracy: 0.3623\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0446 - accuracy: 0.3703\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.9899 - accuracy: 0.3764\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.9377 - accuracy: 0.3895\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8760 - accuracy: 0.4051\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8356 - accuracy: 0.4147\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7796 - accuracy: 0.4304\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7408 - accuracy: 0.4395\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7027 - accuracy: 0.4516\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6245 - accuracy: 0.4632\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5677 - accuracy: 0.4788\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5179 - accuracy: 0.4955\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4609 - accuracy: 0.5081\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.4310 - accuracy: 0.5040\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3889 - accuracy: 0.5197\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3415 - accuracy: 0.5318\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2888 - accuracy: 0.5348\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2597 - accuracy: 0.5489\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2413 - accuracy: 0.5399\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1736 - accuracy: 0.5605\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1289 - accuracy: 0.5716\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0973 - accuracy: 0.5747\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0488 - accuracy: 0.5863\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0191 - accuracy: 0.5974\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.9744 - accuracy: 0.6004\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9380 - accuracy: 0.6090\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8971 - accuracy: 0.6231\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.8726 - accuracy: 0.6271\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.8831 - accuracy: 0.6186\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8677 - accuracy: 0.6171\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.8092 - accuracy: 0.6387\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7599 - accuracy: 0.6473\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7327 - accuracy: 0.6519\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.6932 - accuracy: 0.6650\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6659 - accuracy: 0.6655\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6578 - accuracy: 0.6726\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6254 - accuracy: 0.6741\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5947 - accuracy: 0.6801\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5576 - accuracy: 0.6892\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5287 - accuracy: 0.6993\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5020 - accuracy: 0.7008\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4865 - accuracy: 0.7059\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4729 - accuracy: 0.7059\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4464 - accuracy: 0.7074\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4263 - accuracy: 0.7129\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.4127 - accuracy: 0.7149\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3788 - accuracy: 0.7240\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3623 - accuracy: 0.7260\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3434 - accuracy: 0.7270\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3067 - accuracy: 0.7442\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2808 - accuracy: 0.7528\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2671 - accuracy: 0.7462\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2545 - accuracy: 0.7492\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2553 - accuracy: 0.7442\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2345 - accuracy: 0.7467\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2142 - accuracy: 0.7588\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2074 - accuracy: 0.7553\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1818 - accuracy: 0.7614\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1550 - accuracy: 0.7649\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1319 - accuracy: 0.7694\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1098 - accuracy: 0.7770\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.7795\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0871 - accuracy: 0.7836\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0767 - accuracy: 0.7780\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0592 - accuracy: 0.7856\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0424 - accuracy: 0.7886\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0270 - accuracy: 0.7931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ye9U5Ojq7fxn",
        "outputId": "8ccef125-8f5a-4371-b831-50177fb25036"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYvqqYde7f0D",
        "outputId": "6cbcdabb-82b4-4161-c382-2dc2a2e6eba8"
      },
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills me mean my sleep so sad so quiet break deep deep hes break deep deep touch truth truth could be deep deep come good wanted but new to breeze out that mine fine together found could be so nice deep here be slow and thorough it it so much so much deep deep deep deep hes breeze deep touch youll truth truth dreams truth chiquitita dreams quiet none of you over out that before before found learn would learn could what me before before would night scars scars were deal past past scars scars scars were deal darkest learn chiquitita\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THIZNsx-C2Vb",
        "outputId": "88319e68-e6d8-4492-cbed-320308a62678"
      },
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDxqCdIlC43A",
        "outputId": "a36a2834-fe09-4a28-b2ad-fe733043fa27"
      },
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills and you used it without give and sell so quiet deep deep show broken here again me cause you over for it over give before like it easy go it slow be could that on in they what could hes before come chiquitita see you feel care be felt be end so pain together part before would night city you leave me andante above out your learn hate dreams tell and again and i leave me leave me mean be about are ways slack i and much much much try was moving holds could it leave me before this here\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}