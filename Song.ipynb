{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Song.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0FwXDFlkVipybPnXKa8/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blackcipher101/DeepLearning/blob/master/Song.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooHCHXd147Tl"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAg4Jirr7dTs",
        "outputId": "c14e4f05-5cd2-45f1-fb0e-2ecd3dba2e59"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-28 17:55:29--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.218.101, 172.217.218.100, 172.217.218.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.218.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bmadqr138tak6pvsrenbrpq7p6mkrs23/1606586100000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-11-28 17:55:32--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bmadqr138tak6pvsrenbrpq7p6mkrs23/1606586100000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv       [    <=>             ]  69.08M   103MB/s    in 0.7s    \n",
            "\n",
            "2020-11-28 17:55:33 (103 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMNvVSBr7fh2"
      },
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXJvTl6Z7fl7",
        "outputId": "c4db2049-d7eb-498c-d7ea-d7b71b140221"
      },
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UJwOrbf9Bvq"
      },
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NkHyW0i7fn_",
        "outputId": "460e5144-a688-48b3-bc8a-7c99c0ff4a97"
      },
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Tryi9B7fsu",
        "outputId": "73787fd2-064d-4e77-894b-67911846dbde"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.9843 - accuracy: 0.0293\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.4339 - accuracy: 0.0399\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.3662 - accuracy: 0.0414\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.3110 - accuracy: 0.0378\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.2400 - accuracy: 0.0404\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.1659 - accuracy: 0.0484\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.0978 - accuracy: 0.0479\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.0262 - accuracy: 0.0555\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.9514 - accuracy: 0.0484\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.8665 - accuracy: 0.0636\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.7802 - accuracy: 0.0706\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.6879 - accuracy: 0.0767\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5894 - accuracy: 0.1034\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5013 - accuracy: 0.1145\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.4088 - accuracy: 0.1226\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.3150 - accuracy: 0.1408\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.2455 - accuracy: 0.1615\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.1380 - accuracy: 0.1786\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.0471 - accuracy: 0.1887\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.9581 - accuracy: 0.2003\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.8812 - accuracy: 0.2109\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.8053 - accuracy: 0.2275\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.7320 - accuracy: 0.2346\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6491 - accuracy: 0.2523\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.5818 - accuracy: 0.2689\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.5126 - accuracy: 0.2825\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4448 - accuracy: 0.2987\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.3703 - accuracy: 0.3224\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.3156 - accuracy: 0.3310\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.2482 - accuracy: 0.3476\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.1847 - accuracy: 0.3542\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.1251 - accuracy: 0.3739\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0821 - accuracy: 0.3749\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0399 - accuracy: 0.3870\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.9684 - accuracy: 0.3966\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.9039 - accuracy: 0.4122\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8455 - accuracy: 0.4233\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.7972 - accuracy: 0.4253\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7471 - accuracy: 0.4435\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6883 - accuracy: 0.4506\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.6433 - accuracy: 0.4495\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.6086 - accuracy: 0.4632\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.5619 - accuracy: 0.4793\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.5077 - accuracy: 0.4899\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4687 - accuracy: 0.4965\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.4246 - accuracy: 0.5111\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.4083 - accuracy: 0.5086\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.4484 - accuracy: 0.5020\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3580 - accuracy: 0.5156\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.3050 - accuracy: 0.5313\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2518 - accuracy: 0.5424\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.2001 - accuracy: 0.5530\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.1498 - accuracy: 0.5641\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1206 - accuracy: 0.5616\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0834 - accuracy: 0.5782\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0451 - accuracy: 0.5843\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0245 - accuracy: 0.5832\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.9818 - accuracy: 0.6009\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.9418 - accuracy: 0.6070\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.9072 - accuracy: 0.6171\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8726 - accuracy: 0.6256\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8393 - accuracy: 0.6302\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8113 - accuracy: 0.6342\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7825 - accuracy: 0.6498\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7586 - accuracy: 0.6488\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7503 - accuracy: 0.6589\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7097 - accuracy: 0.6650\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6738 - accuracy: 0.6731\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6440 - accuracy: 0.6821\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.6155 - accuracy: 0.6826\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5780 - accuracy: 0.6942\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.5488 - accuracy: 0.7018\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5263 - accuracy: 0.7053\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.5118 - accuracy: 0.6983\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5218 - accuracy: 0.7059\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4783 - accuracy: 0.7109\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.4465 - accuracy: 0.7225\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4255 - accuracy: 0.7195\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4095 - accuracy: 0.7230\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3835 - accuracy: 0.7286\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4039 - accuracy: 0.7205\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4043 - accuracy: 0.7154\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5442 - accuracy: 0.6837\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4528 - accuracy: 0.6892\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3824 - accuracy: 0.7175\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3158 - accuracy: 0.7321\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2765 - accuracy: 0.7397\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2458 - accuracy: 0.7508\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2205 - accuracy: 0.7543\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1983 - accuracy: 0.7629\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1958 - accuracy: 0.7588\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1762 - accuracy: 0.7649\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1511 - accuracy: 0.7714\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1418 - accuracy: 0.7719\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1168 - accuracy: 0.7795\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0963 - accuracy: 0.7800\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0725 - accuracy: 0.7866\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0650 - accuracy: 0.7861\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0442 - accuracy: 0.7891\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0270 - accuracy: 0.7931\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0108 - accuracy: 0.7916\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9977 - accuracy: 0.7947\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9875 - accuracy: 0.7931\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9783 - accuracy: 0.7982\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9577 - accuracy: 0.7997\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9446 - accuracy: 0.8037\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9365 - accuracy: 0.7972\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9286 - accuracy: 0.8058\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9129 - accuracy: 0.8108\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9022 - accuracy: 0.8093\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8876 - accuracy: 0.8148\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8729 - accuracy: 0.8153\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8874 - accuracy: 0.8088\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9566 - accuracy: 0.7916\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9108 - accuracy: 0.7962\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8853 - accuracy: 0.8063\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8723 - accuracy: 0.8052\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8701 - accuracy: 0.8143\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8394 - accuracy: 0.8204\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8185 - accuracy: 0.8249\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8004 - accuracy: 0.8285\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8856 - accuracy: 0.8108\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8594 - accuracy: 0.8098\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8298 - accuracy: 0.8209\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8007 - accuracy: 0.8244\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7806 - accuracy: 0.8285\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7517 - accuracy: 0.8370\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7425 - accuracy: 0.8406\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7405 - accuracy: 0.8360\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7447 - accuracy: 0.8355\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7195 - accuracy: 0.8476\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7082 - accuracy: 0.8471\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6915 - accuracy: 0.8502\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.8522\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7383 - accuracy: 0.8305\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7600 - accuracy: 0.8204\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7287 - accuracy: 0.8380\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7037 - accuracy: 0.8421\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6867 - accuracy: 0.8542\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6725 - accuracy: 0.8547\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.8542\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6524 - accuracy: 0.8547\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6413 - accuracy: 0.8582\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6330 - accuracy: 0.8628\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6277 - accuracy: 0.8577\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6229 - accuracy: 0.8577\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6159 - accuracy: 0.8648\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6029 - accuracy: 0.8638\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5951 - accuracy: 0.8633\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5888 - accuracy: 0.8663\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5868 - accuracy: 0.8668\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5935 - accuracy: 0.8628\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.8658\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5874 - accuracy: 0.8628\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.8673\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5583 - accuracy: 0.8688\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5515 - accuracy: 0.8729\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5449 - accuracy: 0.8749\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6442 - accuracy: 0.8471\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6154 - accuracy: 0.8547\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5842 - accuracy: 0.8587\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5611 - accuracy: 0.8618\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5479 - accuracy: 0.8708\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.8724\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.8703\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5243 - accuracy: 0.8724\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.8729\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.8789\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.8769\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4977 - accuracy: 0.8739\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.8794\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.8829\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4843 - accuracy: 0.8814\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4814 - accuracy: 0.8799\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.8799\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.8819\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.8850\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.8819\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.8769\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.8850\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.8850\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.8840\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.8855\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.8845\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.8829\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.8915\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.8895\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.8925\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8920\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.8713\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.8784\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.8814\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4536 - accuracy: 0.8865\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.8819\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.8824\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8885\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.8925\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8890\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8940\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ye9U5Ojq7fxn",
        "outputId": "e57340ee-2042-4dba-88e3-56c441225ef4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYvqqYde7f0D",
        "outputId": "a9640ff9-efa7-4619-9ede-e6dd89dd041b"
      },
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills a new song chiquitita every touch leaving know father saw never had talk realized kiss just me dont deeply night sky city night night best truth fingers theyre advice will ever believe that she like talk on had had on had please night still hand night night dont night night night body realized a power bedumbedumdum dont night night house do much to night city night night dont night night night feel park sky realized will on easy what do found so much do what truth could truth truth realized see can one though learn learn learn sure as please\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}